{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code = True) # trust_remote_code = 모델 다운로드에 대한 검증 절차가 생략\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정매핑\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 감정분류 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        # 텍스트 입력 / 토큰화 / 분류\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # 예측하기\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "        \n",
    "        # 분류된 감정 라벨\n",
    "        predicted_emotion = self.label_to_emotion[predicted_label]\n",
    "        \n",
    "        return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 답변 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # 만든 프롬프트를 통해 응답 생성\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_api_key):\n",
    "        \"\"\"\n",
    "        DiaryService 초기화\n",
    "        :param emotion_model_path: KoBERT 감정 분류 모델 경로\n",
    "        :param gemini_api_key: Gemini API 키\n",
    "        \"\"\"\n",
    "        # KoBERT 감정 분류 모델 초기화\n",
    "        self.emotion_classifier = EmotionClassifier()\n",
    "        self.emotion_classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 키 저장\n",
    "        self.gemini_api_key = gemini_api_key\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        :param user_text: 사용자 입력 텍스트\n",
    "        :return: 감정 예측 결과 및 Gemini 응답\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.emotion_classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API 호출 (예제)\n",
    "        response = self.get_gemini_response(user_text)\n",
    "\n",
    "        return {\n",
    "            \"user_text\": user_text,\n",
    "            \"predicted_emotion\": predicted_emotion,\n",
    "            \"response\": response,\n",
    "        }\n",
    "\n",
    "    def get_gemini_response(self, text):\n",
    "        \"\"\"\n",
    "        Gemini API 호출 (예제)\n",
    "        :param text: 사용자 입력 텍스트\n",
    "        :return: Gemini 응답 텍스트\n",
    "        \"\"\"\n",
    "        # 여기에서 실제 Gemini API 호출 로직을 구현하세요.\n",
    "        # 예제에서는 간단히 텍스트를 반환합니다.\n",
    "        return f\"Gemini 응답: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 결과 ---\n",
      "입력 텍스트: 사진에는 사람들이 꽃 구경을 하고있네 다들 웃고있어\n",
      "예측된 감정: 행복\n",
      "Gemini 응답: Gemini 응답: 사진에는 사람들이 꽃 구경을 하고있네 다들 웃고있어\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_key)\n",
    "\n",
    "    # 사용자 입력 텍스트 테스트\n",
    "    user_input = input(\"텍스트를 입력하세요: \")\n",
    "    result = diary_service.process_input(user_input)\n",
    "\n",
    "    print(\"\\n--- 결과 ---\")\n",
    "    print(f\"입력 텍스트: {result['user_text']}\")\n",
    "    print(f\"예측된 감정: {result['predicted_emotion']}\")\n",
    "    print(f\"Gemini 응답: {result['response']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\n",
      "\n",
      "인용이: 오늘 어떤 놀라운 일이 있었나요?\n",
      "\n",
      "인용이: 오늘따라 더 예뻐 보이는 꽃이 있나요?\n",
      "\n",
      "인용이: 오늘 유채꽃을 보니 어떤 점이 가장 놀라웠나요?\n",
      "\n",
      "인용이: 오늘 하루를 싱싱하게 만들어준 것은 무엇이었나요?\n",
      "\n",
      "\n",
      "대화를 종료하고 요약된 일기를 생성합니다...\n",
      "\n",
      "### 일기 작성 (2025-03-02 13:58:29)\n",
      "\n",
      "## 오늘 하루 일기\n",
      "\n",
      "오늘, 누군가가 나를 따라 하는 듯한 느낌을 받았다. 묘한 기분이었다. 그러다 문득, 사람들이 꽃구경하는 모습이 눈에 들어왔다. 다들 웃고 있는 모습이 보기 좋았다. 특히 유채꽃이 눈에 띄었는데, 정말 싱싱하더라. 그 싱싱함 덕분인지, 오늘 하루도 덩달아 싱싱하게 느껴졌다. 유채꽃 덕분에 왠지 모르게 기분 좋은 하루였다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# EmotionClassifier: KoBERT 기반 감정 분류 클래스\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정 매핑 (라벨 번호 -> 감정 이름)\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "\n",
    "        # 모델 예측\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "        # 예측된 감정을 반환\n",
    "        return self.label_to_emotion[predicted_label]\n",
    "\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 질문 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # Generate content using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 대화 내용을 요약하여 일기 형식으로 작성\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "대화내용을 일기형식으로 요약:\n",
    "{conversation_history}\n",
    "일기 형식으로 작성해줘야 해\n",
    "\"\"\"\n",
    "        \n",
    "        # Generate summary using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 요약된 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_api_key):\n",
    "        # KoBERT 기반 감정 분류 모델 초기화\n",
    "        self.classifier = EmotionClassifier()\n",
    "        self.classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 초기화\n",
    "        self.gemini_service = GeminiService(api_key=gemini_api_key)\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API로 질문 생성\n",
    "        response_text = self.gemini_service.generate_response(predicted_emotion, user_text)\n",
    "\n",
    "        return predicted_emotion, response_text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        대화 내용 요약 요청\n",
    "        \"\"\"\n",
    "        return self.gemini_service.summarize_conversation(conversation_history)\n",
    "\n",
    "\n",
    "# 메인 실행 코드 (대화 인터페이스)\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "    gemini_api_key = gemini_key\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_api_key)\n",
    "\n",
    "    print(\"인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\\n\")\n",
    "\n",
    "    conversation_history = \"\"\n",
    "    while True:\n",
    "        # 사용자 입력 받기\n",
    "        user_input = input(\"사용자: \")\n",
    "        \n",
    "        if user_input.strip().lower() == \"그만\":\n",
    "            print(\"\\n대화를 종료하고 요약된 일기를 생성합니다...\\n\")\n",
    "            diary_entry = diary_service.summarize_conversation(conversation_history)\n",
    "            \n",
    "            # 현재 날짜 및 시간 가져오기\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            print(f\"### 일기 작성 ({current_time})\\n\")\n",
    "            print(diary_entry)\n",
    "            break\n",
    "\n",
    "        # 사용자 입력 처리 및 응답 생성\n",
    "        predicted_emotion, gemini_response = diary_service.process_input(user_input)\n",
    "\n",
    "        # 대화 기록 저장\n",
    "        conversation_history += f\"User: {user_input}\\n인용이: {gemini_response}\\n\"\n",
    "\n",
    "        # AI 응답 출력\n",
    "        print(f\"인용이: {gemini_response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
