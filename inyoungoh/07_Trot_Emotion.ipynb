{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© ìƒì„± ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# E5 ì„ë² ë”© ìƒì„± í´ë˜ìŠ¤\n",
    "class E5Embedder:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-large\")\n",
    "        self.model = AutoModel.from_pretrained(\"intfloat/e5-large\")\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ E5 ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach()\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë¡œë“œ\n",
    "df = pd.read_csv('new_trot_clean.csv')\n",
    "\n",
    "# E5 ì„ë² ë”© ìƒì„± ë° ì €ì¥\n",
    "embedder = E5Embedder()\n",
    "\n",
    "if 'embedding' not in df.columns:  # ìµœì´ˆ ì‹¤í–‰ ì‹œë§Œ ì„ë² ë”© ìƒì„±\n",
    "    print(\"ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    df['embedding'] = df['cleaned_lyrics'].apply(lambda x: embedder.get_embedding(x))\n",
    "    df.to_pickle(\"./trot_embeddings.pkl\")  # ì„ë² ë”© í¬í•¨ ë°ì´í„° ì €ì¥\n",
    "else:\n",
    "    df = pd.read_pickle(\"./trot_embeddings.pkl\")  # ì´ë¯¸ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        \"\"\"\n",
    "        KoBERT ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        \"\"\"\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # ê°ì • ë§¤í•‘\n",
    "        self.label_to_emotion = {\n",
    "            0: \"ì¤‘ë¦½\",\n",
    "            1: \"ë†€ëŒ\",\n",
    "            2: \"ë¶„ë…¸\",\n",
    "            3: \"ìŠ¬í””\",\n",
    "            4: \"í–‰ë³µ\",\n",
    "            5: \"í˜ì˜¤\",\n",
    "            6: \"ê³µí¬\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"\n",
    "        í•™ìŠµëœ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        \"\"\"\n",
    "        state_dict = torch.load(model_file, map_location=self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "        \"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Zê°€-í£\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"\n",
    "        ê°ì • ë¶„ë¥˜ ë° ì˜ˆì¸¡\n",
    "        \"\"\"\n",
    "        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° í† í°í™”\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "\n",
    "        # KoBERT ëª¨ë¸ë¡œ ê°ì • ì˜ˆì¸¡\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "        # ë¼ë²¨ì„ ê°ì • ì´ë¦„ìœ¼ë¡œ ë³€í™˜\n",
    "        predicted_emotion = self.label_to_emotion[predicted_label]\n",
    "        \n",
    "        return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°í”„ë ˆì„ êµ¬ì¡°:\n",
      "              title          artist  \\\n",
      "0             ì§„ì •ì¸ê°€ìš”             ì •ì„œì£¼   \n",
      "1    ë©˜í† ë§ (Feat. ê³½ë²”)             ì´ì§€ìš”   \n",
      "2            ì‚¬ë‘ì˜ì‚¼ë§¤ê²½  ëˆ„ë‚˜ë‘˜ (Nunadool)   \n",
      "3  ìœ ë¦¬ê½ƒ (Cover Ver.)             ê¹€ì¤€ì˜   \n",
      "4           ì œëª©ì€ ë‹¹ì‹ ê½ƒ              ë™í›„   \n",
      "\n",
      "                                      cleaned_lyrics  \\\n",
      "0  ë¯¸ë ¨ì—†ë‹¤ ê·¸ ë§ì´ ì§„ì •ì¸ê°€ìš” ëƒ‰ì •í–ˆë˜ ê·¸ ë§ˆìŒì´ ì§„ì •ì¸ê°€ìš” ë°”ë‹·ê°€ë¥¼ ê±°ë‹ë©° ìˆ˜ë†“ì•˜ë˜...   \n",
      "1  ê·¸ëŒ„ ë‚˜ì˜ ë©˜í† ì•¼ ë‚˜ëŠ” ë‹¹ì‹ ì˜ ì—ë„ˆì§€ ì¦ê±°ìš´ í•˜ë£¨ë˜ì„¸ìš” í–‰ë³µí•œ ê¸°ë¶„ ë„ˆë¬´ ì¢‹ì•„ìš” ê·¸...   \n",
      "2  ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì—ë¹ ì ¸ìš” ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì˜ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” í ë»‘ ë¹ ì ¸ë²„ë¦° ë‚´...   \n",
      "3  ìœ ë¦¬ê½ƒì²˜ëŸ¼ ì…ìˆ ë§Œ í›”ì¹˜ê³  ê°€ë²„ë¦° ê·¸ë‚  ê·¸ ì¹´í˜ì— ì§€ìš¸ ìˆ˜ ì—†ëŠ” ë„ˆì˜ í–¥ê¸°ê°€ ì—°ê¸°ì²˜ëŸ¼...   \n",
      "4  ê°€ë¡œë“±ì— ê½ƒì´ í”¼ë„¤ìš” ê·¸ëŒ€ì™€ í•¨ê»˜ ê±°ë‹ ë•Œ ìˆ˜ì¤ì–´í•˜ë˜ ê·¸ ì‚¬ë‘ì— ì´ë¦„ ëª¨ë¥¼ ê½ƒì´ í”¼...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [[tensor(-0.2948), tensor(-0.7847), tensor(0.6...  \n",
      "1  [[tensor(-0.6234), tensor(-0.9389), tensor(0.8...  \n",
      "2  [[tensor(-0.4987), tensor(-1.0133), tensor(0.5...  \n",
      "3  [[tensor(-0.5342), tensor(-0.9054), tensor(0.6...  \n",
      "4  [[tensor(-0.3140), tensor(-1.0779), tensor(0.8...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ê°ì •ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„:\n",
      "              title          artist  \\\n",
      "0             ì§„ì •ì¸ê°€ìš”             ì •ì„œì£¼   \n",
      "1    ë©˜í† ë§ (Feat. ê³½ë²”)             ì´ì§€ìš”   \n",
      "2            ì‚¬ë‘ì˜ì‚¼ë§¤ê²½  ëˆ„ë‚˜ë‘˜ (Nunadool)   \n",
      "3  ìœ ë¦¬ê½ƒ (Cover Ver.)             ê¹€ì¤€ì˜   \n",
      "4           ì œëª©ì€ ë‹¹ì‹ ê½ƒ              ë™í›„   \n",
      "\n",
      "                                      cleaned_lyrics  \\\n",
      "0  ë¯¸ë ¨ì—†ë‹¤ ê·¸ ë§ì´ ì§„ì •ì¸ê°€ìš” ëƒ‰ì •í–ˆë˜ ê·¸ ë§ˆìŒì´ ì§„ì •ì¸ê°€ìš” ë°”ë‹·ê°€ë¥¼ ê±°ë‹ë©° ìˆ˜ë†“ì•˜ë˜...   \n",
      "1  ê·¸ëŒ„ ë‚˜ì˜ ë©˜í† ì•¼ ë‚˜ëŠ” ë‹¹ì‹ ì˜ ì—ë„ˆì§€ ì¦ê±°ìš´ í•˜ë£¨ë˜ì„¸ìš” í–‰ë³µí•œ ê¸°ë¶„ ë„ˆë¬´ ì¢‹ì•„ìš” ê·¸...   \n",
      "2  ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì—ë¹ ì ¸ìš” ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì˜ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” í ë»‘ ë¹ ì ¸ë²„ë¦° ë‚´...   \n",
      "3  ìœ ë¦¬ê½ƒì²˜ëŸ¼ ì…ìˆ ë§Œ í›”ì¹˜ê³  ê°€ë²„ë¦° ê·¸ë‚  ê·¸ ì¹´í˜ì— ì§€ìš¸ ìˆ˜ ì—†ëŠ” ë„ˆì˜ í–¥ê¸°ê°€ ì—°ê¸°ì²˜ëŸ¼...   \n",
      "4  ê°€ë¡œë“±ì— ê½ƒì´ í”¼ë„¤ìš” ê·¸ëŒ€ì™€ í•¨ê»˜ ê±°ë‹ ë•Œ ìˆ˜ì¤ì–´í•˜ë˜ ê·¸ ì‚¬ë‘ì— ì´ë¦„ ëª¨ë¥¼ ê½ƒì´ í”¼...   \n",
      "\n",
      "                                           embedding emotion  \n",
      "0  [[tensor(-0.2948), tensor(-0.7847), tensor(0.6...      ìŠ¬í””  \n",
      "1  [[tensor(-0.6234), tensor(-0.9389), tensor(0.8...      í–‰ë³µ  \n",
      "2  [[tensor(-0.4987), tensor(-1.0133), tensor(0.5...      ìŠ¬í””  \n",
      "3  [[tensor(-0.5342), tensor(-0.9054), tensor(0.6...      ìŠ¬í””  \n",
      "4  [[tensor(-0.3140), tensor(-1.0779), tensor(0.8...      í–‰ë³µ  \n",
      "\n",
      "PKL íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŠ¸ë¡œíŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "song_data_path = \"trot_embeddings.pkl\"  # í¬ë¡¤ë§ëœ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ\n",
    "df = pd.read_pickle(song_data_path)\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print(\"ë°ì´í„°í”„ë ˆì„ êµ¬ì¡°:\")\n",
    "print(df.head())\n",
    "\n",
    "# KoBERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "emotion_model_path = \"new_data_test.pth\"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
    "emotion_classifier = EmotionClassifier()\n",
    "emotion_classifier.load_model(emotion_model_path)\n",
    "\n",
    "# 'emotion' ì»¬ëŸ¼ ì¶”ê°€\n",
    "def classify_emotion(lyrics):\n",
    "    try:\n",
    "        return emotion_classifier.predict_emotion(lyrics)\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "df['emotion'] = df['cleaned_lyrics'].apply(classify_emotion)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nê°ì •ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„:\")\n",
    "print(df.head())\n",
    "\n",
    "# ê²°ê³¼ CSVë¡œ ì €ì¥\n",
    "df.to_pickle(\"./trot_embeddings_emotion.pkl\")\n",
    "print(\"\\nPKL íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>embedding</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì§„ì •ì¸ê°€ìš”</td>\n",
       "      <td>ì •ì„œì£¼</td>\n",
       "      <td>ë¯¸ë ¨ì—†ë‹¤ ê·¸ ë§ì´ ì§„ì •ì¸ê°€ìš” ëƒ‰ì •í–ˆë˜ ê·¸ ë§ˆìŒì´ ì§„ì •ì¸ê°€ìš” ë°”ë‹·ê°€ë¥¼ ê±°ë‹ë©° ìˆ˜ë†“ì•˜ë˜...</td>\n",
       "      <td>[[tensor(-0.2948), tensor(-0.7847), tensor(0.6...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë©˜í† ë§ (Feat. ê³½ë²”)</td>\n",
       "      <td>ì´ì§€ìš”</td>\n",
       "      <td>ê·¸ëŒ„ ë‚˜ì˜ ë©˜í† ì•¼ ë‚˜ëŠ” ë‹¹ì‹ ì˜ ì—ë„ˆì§€ ì¦ê±°ìš´ í•˜ë£¨ë˜ì„¸ìš” í–‰ë³µí•œ ê¸°ë¶„ ë„ˆë¬´ ì¢‹ì•„ìš” ê·¸...</td>\n",
       "      <td>[[tensor(-0.6234), tensor(-0.9389), tensor(0.8...</td>\n",
       "      <td>í–‰ë³µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì‚¬ë‘ì˜ì‚¼ë§¤ê²½</td>\n",
       "      <td>ëˆ„ë‚˜ë‘˜ (Nunadool)</td>\n",
       "      <td>ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì—ë¹ ì ¸ìš” ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì˜ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” í ë»‘ ë¹ ì ¸ë²„ë¦° ë‚´...</td>\n",
       "      <td>[[tensor(-0.4987), tensor(-1.0133), tensor(0.5...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ìœ ë¦¬ê½ƒ (Cover Ver.)</td>\n",
       "      <td>ê¹€ì¤€ì˜</td>\n",
       "      <td>ìœ ë¦¬ê½ƒì²˜ëŸ¼ ì…ìˆ ë§Œ í›”ì¹˜ê³  ê°€ë²„ë¦° ê·¸ë‚  ê·¸ ì¹´í˜ì— ì§€ìš¸ ìˆ˜ ì—†ëŠ” ë„ˆì˜ í–¥ê¸°ê°€ ì—°ê¸°ì²˜ëŸ¼...</td>\n",
       "      <td>[[tensor(-0.5342), tensor(-0.9054), tensor(0.6...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì œëª©ì€ ë‹¹ì‹ ê½ƒ</td>\n",
       "      <td>ë™í›„</td>\n",
       "      <td>ê°€ë¡œë“±ì— ê½ƒì´ í”¼ë„¤ìš” ê·¸ëŒ€ì™€ í•¨ê»˜ ê±°ë‹ ë•Œ ìˆ˜ì¤ì–´í•˜ë˜ ê·¸ ì‚¬ë‘ì— ì´ë¦„ ëª¨ë¥¼ ê½ƒì´ í”¼...</td>\n",
       "      <td>[[tensor(-0.3140), tensor(-1.0779), tensor(0.8...</td>\n",
       "      <td>í–‰ë³µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>ë‚´ì‚¬ë‘ ê»Œë”±ì§€</td>\n",
       "      <td>ê·¸ë¦°</td>\n",
       "      <td>ì–´ë”” ìˆë‚˜ìš” ì–´ë”” ê°”ë‚˜ìš” ë‚´ ì‚¬ë‘ ê»Œë”±ì§€ ë°”ë¼ë§Œ ë´ë„ ë„ˆë¬´ í–‰ë³µí•´ ë‚´ ì‚¬ë‘ ê»Œë”±ì§€ ...</td>\n",
       "      <td>[[tensor(-0.4370), tensor(-0.6369), tensor(0.2...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>ë´„ë‚ ì˜ ì¶˜í–¥ì´</td>\n",
       "      <td>ê¹€ ì†Œí”¼ì•„</td>\n",
       "      <td>ë”°ìŠ¤í•œ ë´„ë°”ëŒ ë¶ˆì–´ì˜¤ë„¤ ì¶˜í–¥ì´ëŠ” ê½ƒê¸¸ì„ ê±¸ì–´ ê·¸ë…€ì˜ ì›ƒìŒ ë´„í–‡ì‚´ ê°™ì•„ ëª¨ë‘ì˜ ì‹œì„  ...</td>\n",
       "      <td>[[tensor(-0.5346), tensor(-0.9237), tensor(0.3...</td>\n",
       "      <td>í–‰ë³µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>ê´œì°®ì•„</td>\n",
       "      <td>ê¹€ë¯¼ì£¼</td>\n",
       "      <td>ë°”ëŒë„ ì ì´ ë“¤ê³  ë‹¬ë¹›ë§ˆì € ìˆ¨ì–´ ë²„ë¦° ë°¤ ë¬´ì—‡ì„ ì°¾ìœ¼ë ¤ê³  ë‚˜ ì—¬ê¸° ì–´ë‘ ì— ì„œìˆë‚˜ ê·“...</td>\n",
       "      <td>[[tensor(-0.2623), tensor(-1.0824), tensor(0.5...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ìë„¤</td>\n",
       "      <td>ì¡°ì¬ê¶Œ</td>\n",
       "      <td>ì •ì‹ ì—†ì´ ë‹¬ë ¤ì™”ëŠ”ë° ì•ë§Œë³´ê³  ë›°ì–´ì™”ëŠ”ë° í•˜ë‚˜ë‘˜ì”© ë– ë‚˜ê³  ë‚˜í™€ë¡œ ë©ê·¸ëŸ¬ë‹ˆ ë‚¨ì•„ ìˆêµ¬ë‚˜...</td>\n",
       "      <td>[[tensor(-0.3968), tensor(-1.1507), tensor(0.4...</td>\n",
       "      <td>ìŠ¬í””</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>ì†Œì¤‘í•œì‚¬ëŒ</td>\n",
       "      <td>ìµœì•¼ë‚˜</td>\n",
       "      <td>ì–¸ì œë‚˜ í•¨ê»˜í•˜ë©´ í–‰ë³µí•œ ì‚¬ëŒ ë‚´ê²Œ ê°€ì¥ ì†Œì¤‘í•œ ì‚¬ëŒ ë‚´ê²Œ ê°€ì¥ ë¯¸ë”ìš´ ì‚¬ëŒ ë‚˜ì—ê²Œ ...</td>\n",
       "      <td>[[tensor(-0.5297), tensor(-1.0843), tensor(0.5...</td>\n",
       "      <td>í–‰ë³µ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                title          artist  \\\n",
       "0               ì§„ì •ì¸ê°€ìš”             ì •ì„œì£¼   \n",
       "1      ë©˜í† ë§ (Feat. ê³½ë²”)             ì´ì§€ìš”   \n",
       "2              ì‚¬ë‘ì˜ì‚¼ë§¤ê²½  ëˆ„ë‚˜ë‘˜ (Nunadool)   \n",
       "3    ìœ ë¦¬ê½ƒ (Cover Ver.)             ê¹€ì¤€ì˜   \n",
       "4             ì œëª©ì€ ë‹¹ì‹ ê½ƒ              ë™í›„   \n",
       "..                ...             ...   \n",
       "340           ë‚´ì‚¬ë‘ ê»Œë”±ì§€              ê·¸ë¦°   \n",
       "341           ë´„ë‚ ì˜ ì¶˜í–¥ì´           ê¹€ ì†Œí”¼ì•„   \n",
       "342               ê´œì°®ì•„             ê¹€ë¯¼ì£¼   \n",
       "343                ìë„¤             ì¡°ì¬ê¶Œ   \n",
       "344             ì†Œì¤‘í•œì‚¬ëŒ             ìµœì•¼ë‚˜   \n",
       "\n",
       "                                        cleaned_lyrics  \\\n",
       "0    ë¯¸ë ¨ì—†ë‹¤ ê·¸ ë§ì´ ì§„ì •ì¸ê°€ìš” ëƒ‰ì •í–ˆë˜ ê·¸ ë§ˆìŒì´ ì§„ì •ì¸ê°€ìš” ë°”ë‹·ê°€ë¥¼ ê±°ë‹ë©° ìˆ˜ë†“ì•˜ë˜...   \n",
       "1    ê·¸ëŒ„ ë‚˜ì˜ ë©˜í† ì•¼ ë‚˜ëŠ” ë‹¹ì‹ ì˜ ì—ë„ˆì§€ ì¦ê±°ìš´ í•˜ë£¨ë˜ì„¸ìš” í–‰ë³µí•œ ê¸°ë¶„ ë„ˆë¬´ ì¢‹ì•„ìš” ê·¸...   \n",
       "2    ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì—ë¹ ì ¸ìš” ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” ì‚¬ë‘ì˜ì‚¼ë§¤ê²½ì— ë¹ ì ¸ìš” í ë»‘ ë¹ ì ¸ë²„ë¦° ë‚´...   \n",
       "3    ìœ ë¦¬ê½ƒì²˜ëŸ¼ ì…ìˆ ë§Œ í›”ì¹˜ê³  ê°€ë²„ë¦° ê·¸ë‚  ê·¸ ì¹´í˜ì— ì§€ìš¸ ìˆ˜ ì—†ëŠ” ë„ˆì˜ í–¥ê¸°ê°€ ì—°ê¸°ì²˜ëŸ¼...   \n",
       "4    ê°€ë¡œë“±ì— ê½ƒì´ í”¼ë„¤ìš” ê·¸ëŒ€ì™€ í•¨ê»˜ ê±°ë‹ ë•Œ ìˆ˜ì¤ì–´í•˜ë˜ ê·¸ ì‚¬ë‘ì— ì´ë¦„ ëª¨ë¥¼ ê½ƒì´ í”¼...   \n",
       "..                                                 ...   \n",
       "340  ì–´ë”” ìˆë‚˜ìš” ì–´ë”” ê°”ë‚˜ìš” ë‚´ ì‚¬ë‘ ê»Œë”±ì§€ ë°”ë¼ë§Œ ë´ë„ ë„ˆë¬´ í–‰ë³µí•´ ë‚´ ì‚¬ë‘ ê»Œë”±ì§€ ...   \n",
       "341  ë”°ìŠ¤í•œ ë´„ë°”ëŒ ë¶ˆì–´ì˜¤ë„¤ ì¶˜í–¥ì´ëŠ” ê½ƒê¸¸ì„ ê±¸ì–´ ê·¸ë…€ì˜ ì›ƒìŒ ë´„í–‡ì‚´ ê°™ì•„ ëª¨ë‘ì˜ ì‹œì„  ...   \n",
       "342  ë°”ëŒë„ ì ì´ ë“¤ê³  ë‹¬ë¹›ë§ˆì € ìˆ¨ì–´ ë²„ë¦° ë°¤ ë¬´ì—‡ì„ ì°¾ìœ¼ë ¤ê³  ë‚˜ ì—¬ê¸° ì–´ë‘ ì— ì„œìˆë‚˜ ê·“...   \n",
       "343  ì •ì‹ ì—†ì´ ë‹¬ë ¤ì™”ëŠ”ë° ì•ë§Œë³´ê³  ë›°ì–´ì™”ëŠ”ë° í•˜ë‚˜ë‘˜ì”© ë– ë‚˜ê³  ë‚˜í™€ë¡œ ë©ê·¸ëŸ¬ë‹ˆ ë‚¨ì•„ ìˆêµ¬ë‚˜...   \n",
       "344  ì–¸ì œë‚˜ í•¨ê»˜í•˜ë©´ í–‰ë³µí•œ ì‚¬ëŒ ë‚´ê²Œ ê°€ì¥ ì†Œì¤‘í•œ ì‚¬ëŒ ë‚´ê²Œ ê°€ì¥ ë¯¸ë”ìš´ ì‚¬ëŒ ë‚˜ì—ê²Œ ...   \n",
       "\n",
       "                                             embedding emotion  \n",
       "0    [[tensor(-0.2948), tensor(-0.7847), tensor(0.6...      ìŠ¬í””  \n",
       "1    [[tensor(-0.6234), tensor(-0.9389), tensor(0.8...      í–‰ë³µ  \n",
       "2    [[tensor(-0.4987), tensor(-1.0133), tensor(0.5...      ìŠ¬í””  \n",
       "3    [[tensor(-0.5342), tensor(-0.9054), tensor(0.6...      ìŠ¬í””  \n",
       "4    [[tensor(-0.3140), tensor(-1.0779), tensor(0.8...      í–‰ë³µ  \n",
       "..                                                 ...     ...  \n",
       "340  [[tensor(-0.4370), tensor(-0.6369), tensor(0.2...      ìŠ¬í””  \n",
       "341  [[tensor(-0.5346), tensor(-0.9237), tensor(0.3...      í–‰ë³µ  \n",
       "342  [[tensor(-0.2623), tensor(-1.0824), tensor(0.5...      ìŠ¬í””  \n",
       "343  [[tensor(-0.3968), tensor(-1.1507), tensor(0.4...      ìŠ¬í””  \n",
       "344  [[tensor(-0.5297), tensor(-1.0843), tensor(0.5...      í–‰ë³µ  \n",
       "\n",
       "[345 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy\n",
    "\n",
    "class SongRecommender:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        df: ë…¸ë˜ ë°ì´í„°ê°€ ë‹´ê¸´ Pandas ë°ì´í„°í”„ë ˆì„\n",
    "            ì»¬ëŸ¼: ['title', 'artist', 'cleaned_lyrics', 'emotion', 'embedding']\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def recommend_song(self, diary_embedding, emotion):\n",
    "        \"\"\"\n",
    "        ê°ì •ì´ ë™ì¼í•œ ë…¸ë˜ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì¶”ì²œ\n",
    "        \"\"\"\n",
    "        # ê°ì •ì´ ë™ì¼í•œ ë…¸ë˜ í•„í„°ë§\n",
    "        filtered_df = self.df[self.df['emotion'] == emotion]\n",
    "\n",
    "        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        similarities = []\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            similarity = cosine_similarity(diary_embedding.numpy(), row['embedding'].numpy())\n",
    "            similarities.append((row['title'], row['artist'], row['cleaned_lyrics'], similarity[0][0]))\n",
    "\n",
    "        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì„ íƒ\n",
    "        if similarities:\n",
    "            best_match = sorted(similarities, key=lambda x: x[3], reverse=True)[0]\n",
    "            return best_match  # (title, artist, lyrics, similarity)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ì˜¤ëŠ˜ì˜ ì¶”ì²œ ê²°ê³¼ ---\n",
      "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
      "ğŸµ ì œëª©: ì–´ëŠ ë¶€ë¶€ ì´ì•¼ê¸°\n",
      "ğŸ‘¤ ê°€ìˆ˜: ì´ì˜ì‹¤\n",
      "ğŸ“œ ê°€ì‚¬:\n",
      "í•´ ì €ë¬´ëŠ” ê³³ì— ì‚¬ë‘ì´ í”¼ë©´ ë‚˜ í–‰ë³µí•  ìˆ˜ ìˆì–´ìš” í•´ ì €ë¬´ëŠ” ê³³ì— ê½ƒì´ í•€ë‹¤ë©´ ë‚˜ ìŠ¬í¼í•˜ì§€ ì•Šì•„ìš” ì–´ë‘ ì´ ì¢‹ì•„ ìš¸ ìˆ˜ ìˆì–´ì„œ ëˆˆë¬¼ë„ ë³´ì´ì§€ ì•Šì•„ ê·¸ ëˆ„ê°€ ìˆì–´ ìš°ë¦¬ ì‚¬ë‘ì„ í•œ ë°œìêµ­ ì´ëŒì–´ì¤„ê¹Œ í•´ ì €ë¬´ëŠ” ê³³ì— í–‰ë³µì´ ìˆë‹¤ë©´ ë‚˜ ë”°ë¼ê°ˆ ìˆ˜ ìˆì–´ìš” ì–´ë‘ ì´ ì¢‹ì•„ ìš¸ ìˆ˜ ìˆì–´ì„œ ëˆˆë¬¼ë„ ë³´ì´ì§€ ì•Šì•„ ê·¸ ëˆ„ê°€ ìˆì–´ ìš°ë¦¬ ì‚¬ë‘ì„ í•œ ë°œìêµ­ ì´ëŒì–´ì¤„ê¹Œ ì´ëŒì–´ì¤„ê¹Œ ì´ëŒì–´ì¤„ê¹Œ í•´ ì €ë¬´ëŠ” ê³³ì— í–‰ë³µì´ ìˆë‹¤ë©´ ë‚˜ ë”°ë¼ê°ˆ ìˆ˜ ìˆì–´ìš”\n",
      "ğŸ”— ìœ ì‚¬ë„ ì ìˆ˜: 0.8805\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ëª¨ë¸ ê²½ë¡œ ë° ë°ì´í„° ë¡œë“œ\n",
    "    emotion_model_path = \"monologg/kobert\"\n",
    "\n",
    "    # ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    emotion_classifier = EmotionClassifier(model_path=emotion_model_path)\n",
    "\n",
    "    # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    recommender = SongRecommender(df)\n",
    "\n",
    "    # ê°ì • í•™ìŠµ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    emotion_classifier.load_model(\"new_data_test.pth\")\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    user_input = input(\"ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "\n",
    "    # ê°ì • ì˜ˆì¸¡\n",
    "    predicted_emotion = emotion_classifier.predict_emotion(user_input)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±\n",
    "    diary_embedding = embedder.get_embedding(user_input)\n",
    "\n",
    "    # ë…¸ë˜ ì¶”ì²œ ì‹¤í–‰\n",
    "    recommended_song = recommender.recommend_song(diary_embedding, predicted_emotion)\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥ (ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…)\n",
    "    print(\"\\n--- ì˜¤ëŠ˜ì˜ ì¶”ì²œ ê²°ê³¼ ---\")\n",
    "    print(f\"ì˜ˆì¸¡ëœ ê°ì •: {predicted_emotion}\")\n",
    "\n",
    "    if recommended_song:\n",
    "        title, artist, lyrics, similarity = recommended_song\n",
    "        print(f\"ğŸµ ì œëª©: {title}\")\n",
    "        print(f\"ğŸ‘¤ ê°€ìˆ˜: {artist}\")\n",
    "        print(f\"ğŸ“œ ê°€ì‚¬:\\n{lyrics}\")\n",
    "        print(f\"ğŸ”— ìœ ì‚¬ë„ ì ìˆ˜: {similarity:.4f}\")\n",
    "    else:\n",
    "        print(\"ì¶”ì²œí•  ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
