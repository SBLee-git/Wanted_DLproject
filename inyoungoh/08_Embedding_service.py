import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification
from sklearn.metrics.pairwise import cosine_similarity
import re


# E5 ì„ë² ë”© ìƒì„± í´ë˜ìŠ¤
class E5Embedder:
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained("intfloat/e5-large")
        self.model = AutoModel.from_pretrained("intfloat/e5-large")

    def get_embedding(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ E5 ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True)
        outputs = self.model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).detach()


# KoBERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ í´ë˜ìŠ¤
class EmotionClassifier:
    def __init__(self, model_path="monologg/kobert", num_labels=7, device=None):
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model.to(self.device)

        # ê°ì • ë§¤í•‘
        self.label_to_emotion = {
            0: "ì¤‘ë¦½",
            1: "ë†€ëŒ",
            2: "ë¶„ë…¸",
            3: "ìŠ¬í””",
            4: "í–‰ë³µ",
            5: "í˜ì˜¤",
            6: "ê³µí¬"
        }

    def load_model(self, model_file):
        """í•™ìŠµëœ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        state_dict = torch.load(model_file, map_location=self.device)
        self.model.load_state_dict(state_dict)

    def preprocess_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        return re.sub("[^0-9a-zA-Zê°€-í£\s+]", "", text)

    def predict_emotion(self, text):
        """ê°ì • ë¶„ë¥˜ ë° ì˜ˆì¸¡"""
        cleaned_text = self.preprocess_text(text)
        encoded_input = self.tokenizer(cleaned_text, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}

        self.model.eval()
        with torch.no_grad():
            outputs = self.model(**encoded_input)
            predicted_label = outputs.logits.argmax(dim=1).item()

        return self.label_to_emotion[predicted_label]


# ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class SongRecommender:
    def __init__(self, df):
        """
        df: ë…¸ë˜ ë°ì´í„°ê°€ ë‹´ê¸´ Pandas ë°ì´í„°í”„ë ˆì„
            ì»¬ëŸ¼: ['title', 'artist', 'cleaned_lyrics', 'emotion', 'embedding']
        """
        self.df = df

    def recommend_song(self, diary_embedding, emotion):
        """
        ê°ì •ì´ ë™ì¼í•œ ë…¸ë˜ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì¶”ì²œ
        """
        # ê°ì •ì´ ë™ì¼í•œ ë…¸ë˜ í•„í„°ë§
        filtered_df = self.df[self.df['emotion'] == emotion]

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (PyTorch ì‚¬ìš©)
        similarities = []
        for _, row in filtered_df.iterrows():
            # í…ì„œë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
            diary_vector = diary_embedding.squeeze()  # (1024,)
            song_vector = row['embedding'].squeeze()  # (1024,)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = torch.nn.functional.cosine_similarity(
                diary_vector, song_vector, dim=0
            ).item()
            similarities.append((row['title'], row['artist'], row['cleaned_lyrics'], similarity))

        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì„ íƒ
        if similarities:
            best_match = sorted(similarities, key=lambda x: x[3], reverse=True)[0]
            return best_match  # (title, artist, lyrics, similarity)
        else:
            return None

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    # ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”
    song_data_path = "trot_embeddings_emotion.pkl"  # ì €ì¥ëœ íŠ¸ë¡œíŠ¸ ë°ì´í„° ê²½ë¡œ
    emotion_model_path = "new_data_test.pth"  # í•™ìŠµëœ KoBERT ëª¨ë¸ ê²½ë¡œ

    # ë°ì´í„°í”„ë ˆì„ ë¡œë“œ
    df = pd.read_pickle(song_data_path)

    # KoBERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    emotion_classifier = EmotionClassifier()
    emotion_classifier.load_model(emotion_model_path)

    # E5 ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embedder = E5Embedder()

    # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    recommender = SongRecommender(df)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (Geminiì—ì„œ ìš”ì•½ëœ ì¼ê¸° ì…ë ¥)
    user_input = input("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")

    # ê°ì • ì˜ˆì¸¡
    predicted_emotion = emotion_classifier.predict_emotion(user_input)

    # ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±
    diary_embedding = embedder.get_embedding(user_input)

    # ë…¸ë˜ ì¶”ì²œ ì‹¤í–‰
    recommended_song = recommender.recommend_song(diary_embedding, predicted_emotion)

    # ê²°ê³¼ ì¶œë ¥ (ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…)
    print("\n--- ë‹¹ì‹ ì˜ ê°ì •ì— ì–´ìš¸ë¦¬ëŠ” íŠ¸ë¡œíŠ¸ ì¶”ì²œ ---")
    print(f"ì˜ˆì¸¡ëœ ê°ì •: {predicted_emotion}")

    if recommended_song:
        title, artist, lyrics, similarity = recommended_song
        print(f"ğŸµ ì œëª©: {title}")
        print(f"ğŸ‘¤ ê°€ìˆ˜: {artist}")
        print(f"ğŸ“œ ê°€ì‚¬:\n{lyrics}")
        print(f"ğŸ”— ìœ ì‚¬ë„ ì ìˆ˜: {similarity:.4f}")
    else:
        print("ì¶”ì²œí•  ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
